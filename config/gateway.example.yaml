# Example LLM Gateway Configuration
# This demonstrates the new model-based configuration structure

server:
  host: "0.0.0.0"
  port: 3000
  cors:
    enabled: true
    origins: ["*"]

availablePlugins:
  - path: "../plugins/model-router/dist/index.js"
  - path: "../plugins/basic-apikey-auth/dist/index.js"
  - path: "../plugins/logger/dist/index.js"
  - module: "@nullplatform/llm-gateway-clickhouse-tracer-plugin"
  - path: "../plugins/regex-hider/dist/index.js"

# Models are the main routing targets
# Each model has a provider configuration and can have custom settings
models:
  # GPT-4 model with OpenAI provider
  - name: gpt
    isDefault: true
    description: "OpenAI models"
    provider:
      type: "openai"
      config:
        apiKey: "${OPENAI_API_KEY}"
        baseUrl: "https://api.openai.com/v1"
        timeout: 30000
        retryAttempts: 3
        model: gpt-4.1-mini
    modelConfig:
      maxTokens: 4096
      temperature: 0.7
    metadata:
      category: "large-language-model"
      cost_tier: "high"
  - name: claude
    isDefault: false
    description: "Anthropic Claude models"
    provider:
      type: "anthropic"
      config:
        apiKey: "${ANTHROPIC_API_KEY}"
        timeout: 30000
        retryAttempts: 3
        model: claude-sonnet-4-20250514
    modelConfig:
      maxTokens: 4096
      temperature: 0.7
    metadata:
      category: "large-language-model"
      cost_tier: "high"
  - name: gpt2
    isDefault: false
    description: "Bad model"
    provider:
      type: "openai"
      config:
        apiKey: "test"
        baseUrl: "http://127.0.0.1:8086"
        retryAttempts: 1
        model: gpt-4.1-mini

  - name: claude
    isDefault: false
    description: "Anthropic Claude models"
    provider:
      type: "anthropic"
      config:
        apiKey: "${ANTHROPIC_API_KEY}"
        timeout: 30000
        retryAttempts: 3
        model: claude-sonnet-4-20250514
    modelConfig:
      maxTokens: 4096
      temperature: 0.7
    metadata:
      category: "large-language-model"
      cost_tier: "high"

projects:
  - name: "colo"
    description: "project example"
    plugins:
      - name: "router"
        type: "model-router"
        config:
          model: "gpt"
          fallbacks:
            - "gpt"
            - "claude"
#      - name: "basic-apikey-auth"
#        type: "basic-apikey-auth"
#        config:
#          apikeys:
#            - "test-key-123"

# Default plugins for all projects
plugins:
  - name: logger
    type: logger
    config:
      level: "info"
      format: "json"
  - name: pii-detection
    type: regex-hider
    config:
      patterns:
        - pattern: "\\b\\d{3}-\\d{2}-\\d{4}\\b"  # SSN format
          replacement: "[REDACTED|SSN]"
        - pattern: "\\b(?:\\d{4}[- ]?){3}\\d{4}\\b"
          replacement: "[REDACTED|CREDIT_CARD]"
        - pattern: "[a-zA-Z0-9_.+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z0-9.]+"  # Email address"
          replacement: "[REDACTED|PII]"
          applyTo: response
  - name: clickhouse-tracer
    type: clickhouse-tracer
    priority: 100
    config:
      clickhouse:
        host: "127.0.0.1"
        username: "test"
        password: "test"
        database: "traces"
      flushInterval: 1000



# Monitoring configuration
monitoring:
  enabled: true
  metrics: ["requests", "latency", "errors", "tokens", "costs"]
  health_check:
    enabled: true
    interval: 30
    endpoint: "/health"

# Logging configuration
logging:
  level: "info"  # debug, info, warn, error
  format: "json"  # json, simple
  destinations: ["console"]  # console, file
  file_path: "./logs/gateway.log"
